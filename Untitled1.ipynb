{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(32, input_shape=(784,)),\n",
    "    Activation('relu'),\n",
    "    Dense(10),\n",
    "    Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For custom metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 329us/step - loss: 0.7126 - acc: 0.5050\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6978 - acc: 0.5280\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6889 - acc: 0.5400\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6902 - acc: 0.5340\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 36us/step - loss: 0.6785 - acc: 0.5660\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6789 - acc: 0.5740\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6746 - acc: 0.5810\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6724 - acc: 0.5920\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6676 - acc: 0.5970\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 35us/step - loss: 0.6632 - acc: 0.6010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1820b53160>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/20\n",
      "1000/1000 [==============================] - ETA: 1s - loss: 2.4404 - acc: 0.132 - 0s 211us/step - loss: 2.4205 - acc: 0.1030\n",
      "Epoch 2/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 2.3552 - acc: 0.1120\n",
      "Epoch 3/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.3374 - acc: 0.0840\n",
      "Epoch 4/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.3304 - acc: 0.1070\n",
      "Epoch 5/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.3169 - acc: 0.0990\n",
      "Epoch 6/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 2.3034 - acc: 0.1230\n",
      "Epoch 7/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.3103 - acc: 0.1160\n",
      "Epoch 8/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.3106 - acc: 0.1190\n",
      "Epoch 9/20\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 2.3010 - acc: 0.1050\n",
      "Epoch 10/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 2.3042 - acc: 0.1200\n",
      "Epoch 11/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.2954 - acc: 0.1210\n",
      "Epoch 12/20\n",
      "1000/1000 [==============================] - 0s 16us/step - loss: 2.3008 - acc: 0.1220\n",
      "Epoch 13/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 2.3008 - acc: 0.1210\n",
      "Epoch 14/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.3014 - acc: 0.1200\n",
      "Epoch 15/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.3007 - acc: 0.1150\n",
      "Epoch 16/20\n",
      "1000/1000 [==============================] - 0s 20us/step - loss: 2.2965 - acc: 0.1100\n",
      "Epoch 17/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.2941 - acc: 0.1260\n",
      "Epoch 18/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 2.2975 - acc: 0.1110\n",
      "Epoch 19/20\n",
      "1000/1000 [==============================] - 0s 18us/step - loss: 2.2928 - acc: 0.1370\n",
      "Epoch 20/20\n",
      "1000/1000 [==============================] - 0s 17us/step - loss: 2.2931 - acc: 0.1260\n",
      "100/100 [==============================] - 0s 431us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "x_train = np.random.random((1000, 20))\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# Dense(64) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 1s 1ms/step - loss: 11.5180 - acc: 0.0900 - val_loss: 11.4928 - val_acc: 0.0500\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 324us/step - loss: 11.5171 - acc: 0.1000 - val_loss: 11.4872 - val_acc: 0.1300\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 322us/step - loss: 11.5172 - acc: 0.0880 - val_loss: 11.4890 - val_acc: 0.1200\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 282us/step - loss: 11.5165 - acc: 0.0960 - val_loss: 11.4870 - val_acc: 0.0700\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 287us/step - loss: 11.5160 - acc: 0.1070 - val_loss: 11.4886 - val_acc: 0.0500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18217ad588>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 10\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=True,\n",
    "               input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Generate dummy training data\n",
    "x_train = np.random.random((1000, timesteps, data_dim))\n",
    "y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'main_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a4049ca1fbc8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauxiliary_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmain_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauxiliary_output\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# This returns a tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'main_input' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "model = Model(inputs=[main_input, auxiliary_input], outputs=[main_output, auxiliary_output])\n",
    "\n",
    "# This returns a tensor\n",
    "inputs = Input(shape=(784,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(data, labels)  # starts training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def myfunc(arg):\n",
    "    return arg + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd10edd8403c42c6950767baba90cb8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.myfunc>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(myfunc, arg=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_func(a, b):\n",
    "    z = 0\n",
    "    for i in range(100):\n",
    "        z = a * np.cos(z + i) + z * np.sin(b - i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dog():\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "    def sit(self):\n",
    "        print(self.name.title() + \" is now sitting\")\n",
    "\n",
    "    def roll_over(self):\n",
    "        print(self.name.title() + \" is now rolling over\")\n",
    "\n",
    "\n",
    "myDog = Dog('Yanan', 12)\n",
    "myDog.sit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
